{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bde109",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing - Versione Integrata\n",
    "\n",
    "**Approccio unificato che combina:**\n",
    "- ✅ **Tuo progetto**: Feature engineering avanzate da purchase orders, gestione batch_id\n",
    "- ✅ **Repository riferimento**: Aggregazione giornaliera (date_arrival, rm_id), Quantile Loss preparation\n",
    "\n",
    "**Pipeline completa**: Raw data → Cleaning → Feature engineering → Daily aggregation → Output per ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a40d1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Data Cleaning & Preprocessing - Versione Integrata\n",
      "   Combinando il meglio del tuo progetto + repository riferimento\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Data Cleaning & Preprocessing - Versione Integrata\")\n",
    "print(\"   Combinando il meglio del tuo progetto + repository riferimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796c03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Receivals dataset: (122590, 10)\n",
      "   Colonne: ['rm_id', 'product_id', 'purchase_order_id', 'purchase_order_item_no', 'receival_item_no', 'batch_id', 'date_arrival', 'receival_status', 'net_weight', 'supplier_id']\n",
      "\n",
      "📋 Purchase Orders dataset: (33171, 12)\n",
      "   Colonne: ['purchase_order_id', 'purchase_order_item_no', 'quantity', 'delivery_date', 'product_id', 'product_version', 'created_date_time', 'modified_date_time', 'unit_id', 'unit', 'status_id', 'status']\n"
     ]
    }
   ],
   "source": [
    "# Carica receivals\n",
    "receivals = pd.read_csv('../../data/kernel/receivals.csv')\n",
    "print(f\"📦 Receivals dataset: {receivals.shape}\")\n",
    "print(f\"   Colonne: {receivals.columns.tolist()}\")\n",
    "\n",
    "# Carica purchase_orders\n",
    "purchase_orders = pd.read_csv('../../data/kernel/purchase_orders.csv')\n",
    "print(f\"\\n📋 Purchase Orders dataset: {purchase_orders.shape}\")\n",
    "print(f\"   Colonne: {purchase_orders.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc1569",
   "metadata": {},
   "source": [
    "## 1. Load Data & Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c695125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Analisi stati di ricezione:\n",
      "receival_status\n",
      "Completed             122448\n",
      "Finished unloading       106\n",
      "Start unloading           32\n",
      "Planned                    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Distribuzione percentuale:\n",
      "receival_status\n",
      "Completed             99.884167\n",
      "Finished unloading     0.086467\n",
      "Start unloading        0.026103\n",
      "Planned                0.003263\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "✅ Mantenuti TUTTI i record: 122590 record\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🔍 Analisi stati di ricezione:\")\n",
    "print(receivals['receival_status'].value_counts())\n",
    "print(f\"\\n📊 Distribuzione percentuale:\")\n",
    "print(receivals['receival_status'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Mantieni TUTTI i record\n",
    "# Nota: Non serve .copy() qui perché il merge subito dopo crea un nuovo DataFrame\n",
    "data_clean = receivals\n",
    "print(f\"\\n✅ Mantenuti TUTTI i record: {len(data_clean)} record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135faf5d",
   "metadata": {},
   "source": [
    "## 2. Merge con Purchase Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aeea402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔗 Merge receivals con purchase_orders...\n",
      "✅ Merge completato: (122590, 15)\n",
      "\n",
      "📊 Record con match in purchase_orders: 122537 (100.0%)\n",
      "📊 Record senza match: 53 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: the two datasets have different time formats, so we need to standardize them before merging\n",
    "\n",
    "# ✅ IMPORTANTE: Facciamo una copia per non modificare gli originali\n",
    "# (utile se vogliamo riutilizzare i dataset originali per debug/confronti)\n",
    "\n",
    "# receivals.csv\n",
    "data_clean = data_clean.copy()  # Copia PRIMA di modificare in-place\n",
    "data_clean['date_arrival'] = pd.to_datetime(\n",
    "    data_clean['date_arrival'], utc=True\n",
    ")\n",
    "\n",
    "# purchase_orders.csv\n",
    "purchase_orders = purchase_orders.copy()  # Copia PRIMA di modificare\n",
    "for col in ['delivery_date', 'created_date_time', 'modified_date_time']:\n",
    "    purchase_orders[col] = pd.to_datetime(\n",
    "        purchase_orders[col], utc=True\n",
    "    )\n",
    "\n",
    "# Merge\n",
    "print(\"\\n🔗 Merge receivals con purchase_orders...\")\n",
    "data_clean = data_clean.merge(\n",
    "    purchase_orders[['purchase_order_id', 'purchase_order_item_no', 'quantity',\n",
    "                     'delivery_date', 'created_date_time', 'status', 'product_version']],\n",
    "    on=['purchase_order_id', 'purchase_order_item_no'],\n",
    "    how='left',\n",
    "    suffixes=('', '_po')\n",
    ")\n",
    "\n",
    "print(f\"✅ Merge completato: {data_clean.shape}\")\n",
    "print(f\"\\n📊 Record con match in purchase_orders: {data_clean['quantity'].notna().sum()} \"\n",
    "      f\"({data_clean['quantity'].notna().sum()/len(data_clean)*100:.1f}%)\")\n",
    "print(f\"📊 Record senza match: {data_clean['quantity'].isna().sum()} \"\n",
    "      f\"({data_clean['quantity'].isna().sum()/len(data_clean)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdb80a",
   "metadata": {},
   "source": [
    "## 3. Target Variable Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3352e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Analisi net_weight (TARGET variable):\n",
      "   Record totali: 122590\n",
      "   Record con net_weight mancante: 68\n",
      "   Record con net_weight = 0: 137\n",
      "   Record con net_weight < 0: 0\n",
      "\n",
      "✅ Dopo pulizia net_weight: 122385 record (rimossi 205)\n",
      "   Percentuale rimossa: 0.2%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n📊 Analisi net_weight (TARGET variable):\")\n",
    "print(f\"   Record totali: {len(data_clean)}\")\n",
    "print(f\"   Record con net_weight mancante: {data_clean['net_weight'].isna().sum()}\")\n",
    "print(f\"   Record con net_weight = 0: {(data_clean['net_weight'] == 0).sum()}\")\n",
    "print(f\"   Record con net_weight < 0: {(data_clean['net_weight'] < 0).sum()}\")\n",
    "\n",
    "# Rimuovi solo record con peso mancante o <= 0\n",
    "# NECESSARIO: net_weight è il target, deve essere valido per il training\n",
    "initial_count = len(data_clean)\n",
    "data_clean = data_clean[data_clean['net_weight'].notna() & (data_clean['net_weight'] > 0)]\n",
    "print(f\"\\n✅ Dopo pulizia net_weight: {len(data_clean)} record (rimossi {initial_count - len(data_clean)})\")\n",
    "print(f\"   Percentuale rimossa: {(initial_count - len(data_clean))/initial_count*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202056d6",
   "metadata": {},
   "source": [
    "## 4. Advanced Feature Engineering (Tuo Progetto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa32455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Analisi batch_id:\n",
      "   Valori totali: 122385\n",
      "   Valori mancanti: 57744 (47.2%)\n",
      "   Valori unici: 64641\n",
      "\n",
      "✅ batch_id trasformato in feature:\n",
      "   - has_batch_id: flag presenza batch\n",
      "   - batch_frequency: frequenza del batch\n",
      "   - batch_mean_weight: peso medio del batch\n",
      "   - batch_std_weight: variabilità del batch\n",
      "   - batch_count: dimensione del batch\n",
      "\n",
      "✅ Colonna originale 'batch_id' rimossa (feature estratte)\n"
     ]
    }
   ],
   "source": [
    "if 'batch_id' in data_clean.columns:\n",
    "    # Analizza batch_id\n",
    "    print(f\"\\n📊 Analisi batch_id:\")\n",
    "    print(f\"   Valori totali: {len(data_clean)}\")\n",
    "    print(f\"   Valori mancanti: {data_clean['batch_id'].isna().sum()} ({data_clean['batch_id'].isna().sum()/len(data_clean)*100:.1f}%)\")\n",
    "    print(f\"   Valori unici: {data_clean['batch_id'].nunique()}\")\n",
    "    \n",
    "    # OPZIONE 1: Crea feature \"has_batch\" (indica se il record ha un batch_id)\n",
    "    data_clean['has_batch_id'] = (~data_clean['batch_id'].isna()).astype(int)\n",
    "    \n",
    "    # OPZIONE 2: Frequency encoding - quante volte appare questo batch_id?\n",
    "    # Utile per capire se è un batch grande o piccolo\n",
    "    batch_counts = data_clean['batch_id'].value_counts().to_dict()\n",
    "    data_clean['batch_frequency'] = data_clean['batch_id'].map(batch_counts).fillna(0)\n",
    "    \n",
    "    # OPZIONE 3: Statistiche aggregate per batch (peso medio del batch)\n",
    "    batch_stats = data_clean.groupby('batch_id')['net_weight'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    batch_stats.columns = ['batch_id', 'batch_mean_weight', 'batch_std_weight', 'batch_count']\n",
    "    data_clean = data_clean.merge(batch_stats, on='batch_id', how='left')\n",
    "    \n",
    "    # Riempi i missing per i record senza batch_id\n",
    "    data_clean['batch_mean_weight'] = data_clean['batch_mean_weight'].fillna(data_clean['net_weight'].mean())\n",
    "    data_clean['batch_std_weight'] = data_clean['batch_std_weight'].fillna(0)\n",
    "    data_clean['batch_count'] = data_clean['batch_count'].fillna(1)\n",
    "    \n",
    "    # Ora puoi eliminare batch_id originale (abbiamo estratto l'informazione utile)\n",
    "    data_clean = data_clean.drop('batch_id', axis=1)\n",
    "    \n",
    "    print(f\"\\n✅ batch_id trasformato in feature:\")\n",
    "    print(f\"   - has_batch_id: flag presenza batch\")\n",
    "    print(f\"   - batch_frequency: frequenza del batch\")\n",
    "    print(f\"   - batch_mean_weight: peso medio del batch\")\n",
    "    print(f\"   - batch_std_weight: variabilità del batch\")\n",
    "    print(f\"   - batch_count: dimensione del batch\")\n",
    "    print(f\"\\n✅ Colonna originale 'batch_id' rimossa (feature estratte)\")\n",
    "else:\n",
    "    print(\"⚠️ Colonna 'batch_id' non trovata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6a63e",
   "metadata": {},
   "source": [
    "## 5. Purchase Order Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b929cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Nuove feature create da purchase_orders:\n",
      "   - delivery_delay_days: ritardo/anticipo consegna\n",
      "   - is_late_delivery: flag consegna in ritardo\n",
      "   - is_early_delivery: flag consegna anticipata\n",
      "   - weight_vs_quantity_ratio: rapporto peso/quantità\n",
      "   - weight_quantity_diff: differenza peso-quantità\n",
      "   - order_to_arrival_days: giorni da ordine ad arrivo\n",
      "\n",
      "📊 Statistiche ritardi:\n",
      "   Consegne in ritardo: 9855 (8.1%)\n",
      "   Consegne anticipate: 108839 (88.9%)\n",
      "   Ritardo medio: -35.6 giorni\n",
      "   Ritardo mediano: -15.0 giorni\n"
     ]
    }
   ],
   "source": [
    "# Feature: Ritardo di consegna (differenza tra data arrivo e data prevista)\n",
    "data_clean['delivery_delay_days'] = (data_clean['date_arrival'] - data_clean['delivery_date']).dt.days\n",
    "data_clean['is_late_delivery'] = (data_clean['delivery_delay_days'] > 0).astype(int)\n",
    "data_clean['is_early_delivery'] = (data_clean['delivery_delay_days'] < 0).astype(int)\n",
    "\n",
    "# Feature: Differenza tra peso ricevuto e quantità ordinata\n",
    "data_clean['weight_vs_quantity_ratio'] = data_clean['net_weight'] / data_clean['quantity'].replace(0, np.nan)\n",
    "data_clean['weight_quantity_diff'] = data_clean['net_weight'] - data_clean['quantity']\n",
    "\n",
    "# Feature: Tempo tra creazione ordine e arrivo\n",
    "data_clean['order_to_arrival_days'] = (data_clean['date_arrival'] - data_clean['created_date_time']).dt.days\n",
    "\n",
    "print(f\"\\n✅ Nuove feature create da purchase_orders:\")\n",
    "print(f\"   - delivery_delay_days: ritardo/anticipo consegna\")\n",
    "print(f\"   - is_late_delivery: flag consegna in ritardo\")\n",
    "print(f\"   - is_early_delivery: flag consegna anticipata\")\n",
    "print(f\"   - weight_vs_quantity_ratio: rapporto peso/quantità\")\n",
    "print(f\"   - weight_quantity_diff: differenza peso-quantità\")\n",
    "print(f\"   - order_to_arrival_days: giorni da ordine ad arrivo\")\n",
    "\n",
    "# Mostra statistiche\n",
    "print(f\"\\n📊 Statistiche ritardi:\")\n",
    "print(f\"   Consegne in ritardo: {data_clean['is_late_delivery'].sum()} ({data_clean['is_late_delivery'].mean()*100:.1f}%)\")\n",
    "print(f\"   Consegne anticipate: {data_clean['is_early_delivery'].sum()} ({data_clean['is_early_delivery'].mean()*100:.1f}%)\")\n",
    "print(f\"   Ritardo medio: {data_clean['delivery_delay_days'].mean():.1f} giorni\")\n",
    "print(f\"   Ritardo mediano: {data_clean['delivery_delay_days'].median():.1f} giorni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a49cc",
   "metadata": {},
   "source": [
    "## 6. Missing Values Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf878066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Missing values dopo merge e nuove feature:\n",
      "rm_id                       2\n",
      "product_id                  2\n",
      "purchase_order_id           2\n",
      "purchase_order_item_no      2\n",
      "quantity                    2\n",
      "delivery_date               2\n",
      "created_date_time           2\n",
      "status                      2\n",
      "product_version             2\n",
      "delivery_delay_days         2\n",
      "weight_vs_quantity_ratio    2\n",
      "weight_quantity_diff        2\n",
      "order_to_arrival_days       2\n",
      "dtype: int64\n",
      "\n",
      "✅ Missing values gestiti con strategie domain-specific\n",
      "   (Feature engineering > MICE per questo tipo di missing)\n",
      "📊 Dataset finale pronto per feature engineering: 122385 record\n",
      "📊 Numero di colonne: 25\n",
      "\n",
      "📋 Colonne finali:\n",
      "['rm_id', 'product_id', 'purchase_order_id', 'purchase_order_item_no', 'receival_item_no', 'date_arrival', 'receival_status', 'net_weight', 'supplier_id', 'quantity', 'delivery_date', 'created_date_time', 'status', 'product_version', 'has_batch_id', 'batch_frequency', 'batch_mean_weight', 'batch_std_weight', 'batch_count', 'delivery_delay_days', 'is_late_delivery', 'is_early_delivery', 'weight_vs_quantity_ratio', 'weight_quantity_diff', 'order_to_arrival_days']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_order_id</th>\n",
       "      <th>purchase_order_item_no</th>\n",
       "      <th>receival_item_no</th>\n",
       "      <th>date_arrival</th>\n",
       "      <th>receival_status</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>...</th>\n",
       "      <th>batch_frequency</th>\n",
       "      <th>batch_mean_weight</th>\n",
       "      <th>batch_std_weight</th>\n",
       "      <th>batch_count</th>\n",
       "      <th>delivery_delay_days</th>\n",
       "      <th>is_late_delivery</th>\n",
       "      <th>is_early_delivery</th>\n",
       "      <th>weight_vs_quantity_ratio</th>\n",
       "      <th>weight_quantity_diff</th>\n",
       "      <th>order_to_arrival_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208545.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-15 11:34:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>11420.0</td>\n",
       "      <td>52062</td>\n",
       "      <td>1975000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>-1963580.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208545.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-06-15 11:34:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>13760.0</td>\n",
       "      <td>52062</td>\n",
       "      <td>1975000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>-1961240.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208490.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-15 11:38:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>11281.0</td>\n",
       "      <td>50468</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>-1488719.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208490.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-06-15 11:38:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>13083.0</td>\n",
       "      <td>50468</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>-1486917.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>379.0</td>\n",
       "      <td>91900296.0</td>\n",
       "      <td>210435.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-15 11:40:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>23910.0</td>\n",
       "      <td>52577</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191280</td>\n",
       "      <td>-101090.0</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>389.0</td>\n",
       "      <td>91900330.0</td>\n",
       "      <td>208535.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-15 11:43:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>8680.0</td>\n",
       "      <td>55251</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>-341320.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208532.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-15 11:46:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>20023</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>-3485160.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>369.0</td>\n",
       "      <td>91900146.0</td>\n",
       "      <td>208532.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-06-15 11:46:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>6745.0</td>\n",
       "      <td>20023</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>-593255.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>366.0</td>\n",
       "      <td>91900160.0</td>\n",
       "      <td>208532.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-06-15 11:46:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>20023</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>-596985.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>365.0</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>208537.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-06-16 06:26:00+00:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>25060.0</td>\n",
       "      <td>50387</td>\n",
       "      <td>6575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12987.088271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>-6549940.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rm_id  product_id  purchase_order_id  purchase_order_item_no  \\\n",
       "0  365.0  91900143.0           208545.0                    10.0   \n",
       "1  365.0  91900143.0           208545.0                    10.0   \n",
       "2  365.0  91900143.0           208490.0                    10.0   \n",
       "3  365.0  91900143.0           208490.0                    10.0   \n",
       "4  379.0  91900296.0           210435.0                    20.0   \n",
       "5  389.0  91900330.0           208535.0                    30.0   \n",
       "6  365.0  91900143.0           208532.0                    10.0   \n",
       "7  369.0  91900146.0           208532.0                    30.0   \n",
       "8  366.0  91900160.0           208532.0                    20.0   \n",
       "9  365.0  91900143.0           208537.0                    10.0   \n",
       "\n",
       "   receival_item_no              date_arrival receival_status  net_weight  \\\n",
       "0                 1 2004-06-15 11:34:00+00:00       Completed     11420.0   \n",
       "1                 2 2004-06-15 11:34:00+00:00       Completed     13760.0   \n",
       "2                 1 2004-06-15 11:38:00+00:00       Completed     11281.0   \n",
       "3                 2 2004-06-15 11:38:00+00:00       Completed     13083.0   \n",
       "4                 1 2004-06-15 11:40:00+00:00       Completed     23910.0   \n",
       "5                 1 2004-06-15 11:43:00+00:00       Completed      8680.0   \n",
       "6                 1 2004-06-15 11:46:00+00:00       Completed     14840.0   \n",
       "7                 2 2004-06-15 11:46:00+00:00       Completed      6745.0   \n",
       "8                 3 2004-06-15 11:46:00+00:00       Completed      3015.0   \n",
       "9                 1 2004-06-16 06:26:00+00:00       Completed     25060.0   \n",
       "\n",
       "   supplier_id   quantity  ... batch_frequency batch_mean_weight  \\\n",
       "0        52062  1975000.0  ...             0.0      12987.088271   \n",
       "1        52062  1975000.0  ...             0.0      12987.088271   \n",
       "2        50468  1500000.0  ...             0.0      12987.088271   \n",
       "3        50468  1500000.0  ...             0.0      12987.088271   \n",
       "4        52577   125000.0  ...             0.0      12987.088271   \n",
       "5        55251   350000.0  ...             0.0      12987.088271   \n",
       "6        20023  3500000.0  ...             0.0      12987.088271   \n",
       "7        20023   600000.0  ...             0.0      12987.088271   \n",
       "8        20023   600000.0  ...             0.0      12987.088271   \n",
       "9        50387  6575000.0  ...             0.0      12987.088271   \n",
       "\n",
       "  batch_std_weight  batch_count  delivery_delay_days  is_late_delivery  \\\n",
       "0              0.0          1.0               -199.0                 0   \n",
       "1              0.0          1.0               -199.0                 0   \n",
       "2              0.0          1.0               -199.0                 0   \n",
       "3              0.0          1.0               -199.0                 0   \n",
       "4              0.0          1.0                -15.0                 0   \n",
       "5              0.0          1.0               -199.0                 0   \n",
       "6              0.0          1.0               -199.0                 0   \n",
       "7              0.0          1.0               -199.0                 0   \n",
       "8              0.0          1.0               -199.0                 0   \n",
       "9              0.0          1.0               -198.0                 0   \n",
       "\n",
       "   is_early_delivery  weight_vs_quantity_ratio  weight_quantity_diff  \\\n",
       "0                  1                  0.005782            -1963580.0   \n",
       "1                  1                  0.006967            -1961240.0   \n",
       "2                  1                  0.007521            -1488719.0   \n",
       "3                  1                  0.008722            -1486917.0   \n",
       "4                  1                  0.191280             -101090.0   \n",
       "5                  1                  0.024800             -341320.0   \n",
       "6                  1                  0.004240            -3485160.0   \n",
       "7                  1                  0.011242             -593255.0   \n",
       "8                  1                  0.005025             -596985.0   \n",
       "9                  1                  0.003811            -6549940.0   \n",
       "\n",
       "   order_to_arrival_days  \n",
       "0                  153.0  \n",
       "1                  153.0  \n",
       "2                  158.0  \n",
       "3                  158.0  \n",
       "4                  -10.0  \n",
       "5                  153.0  \n",
       "6                  153.0  \n",
       "7                  153.0  \n",
       "8                  153.0  \n",
       "9                  154.0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n📊 Missing values dopo merge e nuove feature:\")\n",
    "missing_summary = data_clean.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "print(missing_summary)\n",
    "\n",
    "# Strategia 1: IDs - Imputa con -1 (indica assenza/non trovato)\n",
    "data_clean['rm_id'] = data_clean['rm_id'].fillna(-1)\n",
    "data_clean['product_id'] = data_clean['product_id'].fillna(-1)\n",
    "data_clean['purchase_order_id'] = data_clean['purchase_order_id'].fillna(-1)\n",
    "data_clean['purchase_order_item_no'] = data_clean['purchase_order_item_no'].fillna(-1)\n",
    "\n",
    "# Strategia 2: Feature numeriche da PO - Imputa con 0 (indica nessun match)\n",
    "# Questo è più informativo di MICE perché preserva il significato strutturale\n",
    "numeric_features = ['delivery_delay_days', 'weight_vs_quantity_ratio', 'weight_quantity_diff', \n",
    "                    'order_to_arrival_days', 'quantity']\n",
    "for col in numeric_features:\n",
    "    if col in data_clean.columns:\n",
    "        data_clean[col] = data_clean[col].fillna(0)\n",
    "\n",
    "# Strategia 3: Categorici - Imputa con \"Unknown\"\n",
    "if 'status' in data_clean.columns:\n",
    "    data_clean['status'] = data_clean['status'].fillna('Unknown')\n",
    "\n",
    "print(f\"\\n✅ Missing values gestiti con strategie domain-specific\")\n",
    "print(f\"   (Feature engineering > MICE per questo tipo di missing)\")\n",
    "print(f\"📊 Dataset finale pronto per feature engineering: {len(data_clean)} record\")\n",
    "print(f\"📊 Numero di colonne: {len(data_clean.columns)}\")\n",
    "print(f\"\\n📋 Colonne finali:\")\n",
    "print(data_clean.columns.tolist())\n",
    "\n",
    "data_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7872b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset dettagliato salvato: (122385, 25)\n",
      "   Prossimo step: Aggregazione giornaliera per repository reference approach\n"
     ]
    }
   ],
   "source": [
    "# Salva dataset intermedio (record-level con tutte le feature)\n",
    "data_clean.to_csv('data_clean_detailed.csv', index=False)\n",
    "print(f\"✅ Dataset dettagliato salvato: {data_clean.shape}\")\n",
    "print(\"   Prossimo step: Aggregazione giornaliera per repository reference approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc7d84",
   "metadata": {},
   "source": [
    "## 7. Daily Aggregation (Repository Reference Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff17ef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Prima dell'aggregazione: 122385 record\n",
      "✅ DOPO aggregazione: 41907 record\n",
      "📊 Riduzione: 122385 → 41907 (34.2%)\n",
      "📊 Materiali unici: 204\n",
      "📊 Range date: 2004-06-15 00:00:00 → 2024-12-19 00:00:00\n",
      "\n",
      "📈 Target Analysis (net_weight) dopo aggregazione:\n",
      "   Media: 37927 kg\n",
      "   Mediana: 22998 kg\n",
      "   Std: 48486 kg\n",
      "   Zero values: 0 (0.0%)\n",
      "\n",
      "✅ Dataset finale salvato: 'data_clean.csv' ((41907, 9))\n",
      "🎯 PRONTO per feature engineering avanzato!\n",
      "✅ DOPO aggregazione: 41907 record\n",
      "📊 Riduzione: 122385 → 41907 (34.2%)\n",
      "📊 Materiali unici: 204\n",
      "📊 Range date: 2004-06-15 00:00:00 → 2024-12-19 00:00:00\n",
      "\n",
      "📈 Target Analysis (net_weight) dopo aggregazione:\n",
      "   Media: 37927 kg\n",
      "   Mediana: 22998 kg\n",
      "   Std: 48486 kg\n",
      "   Zero values: 0 (0.0%)\n",
      "\n",
      "✅ Dataset finale salvato: 'data_clean.csv' ((41907, 9))\n",
      "🎯 PRONTO per feature engineering avanzato!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_arrival</th>\n",
       "      <th>rm_id</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>num_deliveries</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>delivery_delay_days</th>\n",
       "      <th>receival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>365.0</td>\n",
       "      <td>83784.0</td>\n",
       "      <td>7</td>\n",
       "      <td>52062</td>\n",
       "      <td>91900143.0</td>\n",
       "      <td>16400000.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>366.0</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20023</td>\n",
       "      <td>91900160.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>368.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57292</td>\n",
       "      <td>91900170.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>369.0</td>\n",
       "      <td>6745.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20023</td>\n",
       "      <td>91900146.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>379.0</td>\n",
       "      <td>23910.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52577</td>\n",
       "      <td>91900296.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_arrival  rm_id  net_weight  num_deliveries  supplier_id  product_id  \\\n",
       "0   2004-06-15  365.0     83784.0               7        52062  91900143.0   \n",
       "1   2004-06-15  366.0      3015.0               1        20023  91900160.0   \n",
       "2   2004-06-15  368.0     13500.0               1        57292  91900170.0   \n",
       "3   2004-06-15  369.0      6745.0               1        20023  91900146.0   \n",
       "4   2004-06-15  379.0     23910.0               1        52577  91900296.0   \n",
       "\n",
       "     quantity  delivery_delay_days receival_status  \n",
       "0  16400000.0               -199.0       Completed  \n",
       "1    600000.0               -199.0       Completed  \n",
       "2     75000.0                -15.0       Completed  \n",
       "3    600000.0               -199.0       Completed  \n",
       "4    125000.0                -15.0       Completed  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ AGGREGAZIONE GIORNALIERA: Repository Reference Approach\n",
    "# Aggrega per (date_arrival, rm_id) come nel repository di riferimento\n",
    "\n",
    "# Converti date_arrival a solo data (rimuovi time component)\n",
    "data_clean['date_only'] = data_clean['date_arrival'].dt.date\n",
    "data_clean['date_only'] = pd.to_datetime(data_clean['date_only'])\n",
    "\n",
    "print(f\"📊 Prima dell'aggregazione: {len(data_clean)} record\")\n",
    "\n",
    "# Aggrega per (data, rm_id) - core del repository di riferimento\n",
    "daily_receivals = data_clean.groupby(['date_only', 'rm_id'], as_index=False).agg({\n",
    "    'net_weight': 'sum',  # TARGET: Somma peso giornaliero per materiale\n",
    "    'purchase_order_id': 'count',  # Numero di delivery events\n",
    "    'supplier_id': 'first',  # Info supplier\n",
    "    'product_id': 'first',  # Info prodotto\n",
    "    'quantity': 'sum',  # Somma quantità totale giornaliera\n",
    "    'delivery_delay_days': 'mean',  # Media ritardo giornaliero\n",
    "    'receival_status': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]  # Status più frequente\n",
    "}).rename(columns={\n",
    "    'date_only': 'date_arrival',\n",
    "    'purchase_order_id': 'num_deliveries'\n",
    "})\n",
    "\n",
    "print(f\"✅ DOPO aggregazione: {len(daily_receivals)} record\")\n",
    "print(f\"📊 Riduzione: {len(data_clean)} → {len(daily_receivals)} ({len(daily_receivals)/len(data_clean)*100:.1f}%)\")\n",
    "print(f\"📊 Materiali unici: {daily_receivals['rm_id'].nunique()}\")\n",
    "print(f\"📊 Range date: {daily_receivals['date_arrival'].min()} → {daily_receivals['date_arrival'].max()}\")\n",
    "\n",
    "# Analisi target dopo aggregazione (importante per Quantile Loss)\n",
    "print(f\"\\n📈 Target Analysis (net_weight) dopo aggregazione:\")\n",
    "print(f\"   Media: {daily_receivals['net_weight'].mean():.0f} kg\")\n",
    "print(f\"   Mediana: {daily_receivals['net_weight'].median():.0f} kg\")\n",
    "print(f\"   Std: {daily_receivals['net_weight'].std():.0f} kg\")\n",
    "print(f\"   Zero values: {(daily_receivals['net_weight'] == 0).sum()} ({(daily_receivals['net_weight'] == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "# Salva dataset finale per feature engineering\n",
    "daily_receivals.to_csv('data_clean.csv', index=False)\n",
    "print(f\"\\n✅ Dataset finale salvato: 'data_clean.csv' ({daily_receivals.shape})\")\n",
    "print(\"🎯 PRONTO per feature engineering avanzato!\")\n",
    "\n",
    "daily_receivals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae8339",
   "metadata": {},
   "source": [
    "## ✅ Data Cleaning Completato - Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61168fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "✅ DATA CLEANING COMPLETATO - VERSIONE INTEGRATA\n",
      "================================================================================\n",
      "\n",
      "🎯 APPROCCIO UNIFICATO IMPLEMENTATO:\n",
      "\n",
      "1. 📊 TUO PROGETTO (Advanced Features):\n",
      "   ✅ Batch ID feature engineering \n",
      "   ✅ Purchase Order features (ritardi, ratio peso/quantità)\n",
      "   ✅ Missing values gestiti con domain knowledge\n",
      "   ✅ Feature da temporal data\n",
      "\n",
      "2. 📈 REPOSITORY RIFERIMENTO (Data Structure):\n",
      "   ✅ Aggregazione giornaliera (date_arrival, rm_id)\n",
      "   ✅ Riduzione dataset da 122k a 42k record (-66%)\n",
      "   ✅ Target preparation per Quantile Loss\n",
      "   ✅ Time-series ready structure\n",
      "\n",
      "📊 OUTPUT FINALE:\n",
      "   File: data_clean.csv\n",
      "   Shape: (41907, 9)\n",
      "   Columns: ['date_arrival', 'rm_id', 'net_weight', 'num_deliveries', 'supplier_id', 'product_id', 'quantity', 'delivery_delay_days', 'receival_status']\n",
      "   Target: net_weight (media 37927 kg)\n",
      "\n",
      "🚀 PROSSIMO STEP: feature_engineering.ipynb\n",
      "   Input: data_clean.csv \n",
      "   Processo: 48+ advanced features per ML\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"✅ DATA CLEANING COMPLETATO - VERSIONE INTEGRATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "🎯 APPROCCIO UNIFICATO IMPLEMENTATO:\n",
    "\n",
    "1. 📊 TUO PROGETTO (Advanced Features):\n",
    "   ✅ Batch ID feature engineering \n",
    "   ✅ Purchase Order features (ritardi, ratio peso/quantità)\n",
    "   ✅ Missing values gestiti con domain knowledge\n",
    "   ✅ Feature da temporal data\n",
    "\n",
    "2. 📈 REPOSITORY RIFERIMENTO (Data Structure):\n",
    "   ✅ Aggregazione giornaliera (date_arrival, rm_id)\n",
    "   ✅ Riduzione dataset da 122k a 42k record (-66%)\n",
    "   ✅ Target preparation per Quantile Loss\n",
    "   ✅ Time-series ready structure\n",
    "\n",
    "📊 OUTPUT FINALE:\n",
    "   File: data_clean.csv\n",
    "   Shape: {daily_receivals.shape}\n",
    "   Columns: {list(daily_receivals.columns)}\n",
    "   Target: net_weight (media {daily_receivals['net_weight'].mean():.0f} kg)\n",
    "   \n",
    "🚀 PROSSIMO STEP: feature_engineering.ipynb\n",
    "   Input: data_clean.csv \n",
    "   Processo: 48+ advanced features per ML\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntnu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
